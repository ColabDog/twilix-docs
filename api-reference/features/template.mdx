---
title: Template Query
api: "POST https://app.twilix.io/api/v1/collection/template"
description: "More steerable control over prompting and output formats"
---

For users wanting more flexible control over prompting and outputs as part of their 
RAG solution, they can do this with our **template** endpoint.

You want to use this endpoint if you are looking for: 
  - More fine-grained control over what the model outputs such as specifically HTML or Markdown.
  - More steerable inputs where you want to provide an example response before adding references
into the prompt.

<ParamField body="collection" type="string" required>
  The collection to query.
</ParamField>
<ParamField body="userInput" type="string" required>
  The template that you want to use. This template uses a `reference` magic in order to provide 
  users with more flexible control over their LLM outputs. 
  
  An example template that is looking for just the returned Markdown could be:
  ```
You are a cybersecurity consultant, can users help provide
a clearer understanding of what is happening? Return 
this in Markdown with clear headings to separate it out.
{reference}
Markdown:
  ```
  
  On our backend, we replace reference with the relevant `promptFields` that you supply. If None
  is supplied, then it uses all fields in a collection.
  
</ParamField>
<ParamField body="promptFields" type="array">
  The fields that you want to use to feed into the prompt template.
</ParamField>
<ParamField body="fields" type="array">
  The fields that you want to be returned as reference. If not specified, it
  returns all fields as reference.
</ParamField>
<ParamField body="conversationID" type="string">
  The conversation ID. This is returned in the response so you can use the one
  that has been automatically generated for you or you can also supply your own
  to keep track of the conversation on your side.
</ParamField>
<ParamField body="minimumScore" type="float">
  The minimum rerank score.
</ParamField>
<Snippet file="param-limit.mdx" />
<Snippet file="param-include-moderation.mdx" />
<Snippet file="param-stream.mdx" />
<Snippet file="header-application-type.mdx" />

<Accordion title="JavaScript Streaming Example">
  Since it could take up to a few seconds for the answer to complete. Streaming
  is encouraged for the best user experience.

You can pass in `stream=true` in the request to enable streaming response, and
easily setup stream handling
with Microsoft's
[fetch-event-source](https://www.npmjs.com/package/@microsoft/fetch-event-source)
package.

{" "}

<Snippet file="react-streaming-example-copilot.mdx" />

The event stream looks like this:

{" "}

<Snippet file="sample-event-stream.mdx" />

</Accordion>

<Accordion title="JavaScript No Streaming Example">
If latency is not a concern, you can alternatively use the normal calling method and wait for the entire response.

Note it could take up to a few seconds for the answer to complete.

{" "}

<Snippet file="react-normal-example-copilot.mdx" />

</Accordion>
